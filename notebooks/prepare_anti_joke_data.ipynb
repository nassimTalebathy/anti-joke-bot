{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97df8f-d219-42ca-b8e6-9d3d0f80e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AdaptiveEmbedding, AutoModelForSeq2SeqLM, AutoTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750c0e5-ea4e-4d1c-924c-bbfc069e53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-nli-mean-tokens'\n",
    "\n",
    "st1 = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72479ea8-7c9f-4c7a-9122-85c0a5a303c9",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "- Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is `\\n\\n###\\n\\n`. The separator should not appear elsewhere in any prompt.\n",
    "\n",
    "- Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "\n",
    "- Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be `\\n`, `###`, or any other token that does not appear in any completion.\n",
    "\n",
    "- For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dbad29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd74c1c-e159-46c1-8748-8ed903f9cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# add parent to path\n",
    "path = os.path.abspath(os.path.pardir)\n",
    "if path not in sys.path:\n",
    "  sys.path.append(path)\n",
    "\n",
    "import src.utils as utils\n",
    "from src.utils import *\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf452048-f051-47b1-a783-db81587e604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    tdf = df.copy()\n",
    "    tdf.drop_duplicates(inplace=True)\n",
    "    tdf.dropna(inplace=True)\n",
    "    tdf.reset_index(drop=True, inplace=True)\n",
    "    for col in tdf:\n",
    "        tdf[col] = tdf[col].str.strip().str.replace('\\n',' ').str.strip()\n",
    "    tdf['q_a'] = tdf['question'] + ' ' + tdf['answer']\n",
    "    # Prompt\n",
    "    tdf['prompt'] = prep_question(tdf['question']) + prep_answer(tdf['answer'])\n",
    "    ###\n",
    "    vecs = st1.encode(\n",
    "        tdf['q_a'].values,\n",
    "        batch_size=16,\n",
    "        show_progress_bar=True,\n",
    "        output_value='sentence_embedding',\n",
    "    )\n",
    "    vec_df = pd.DataFrame(vecs, index=tdf.index)\n",
    "    vec_df.columns = [f'embedding_{i}' for i in vec_df.columns]\n",
    "    tdf = pd.concat((tdf,vec_df), axis=1)\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657636af-396d-4d01-82f7-e25133f37c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "jokes = pd.read_csv('../data/anti_jokes_raw.csv', sep='\\t')\n",
    "jokes = process(jokes.head(20))\n",
    "print(jokes.shape)\n",
    "jokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69db28a-387e-4d7c-b5b6-fbed0407952f",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe92aac-e470-4a47-b4bb-a2f3dd2bdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jokes['q_a'][:6].values\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a17e1-ac9f-429a-9c9f-9d5aa01ca547",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = st1.encode(\n",
    "    temp,\n",
    "    batch_size=20,\n",
    "    show_progress_bar=True,\n",
    "    output_value=None,\n",
    ")\n",
    "vecs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef275ea4-4c2d-43fa-8b3b-85ece8631e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:v.shape for k,v in vecs[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1cc73-a8b7-49ce-a6d8-c9a046f914fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs[0]['sentence_embedding'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71c69f-dcaf-406d-b733-99afc4726271",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = [v['sentence_embedding'] for v in vecs]\n",
    "v2 = torch.vstack(v2)\n",
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe16ac0-aa3c-4fc1-aef4-b170e2445fd9",
   "metadata": {},
   "source": [
    "## Cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a4c50-fc26-4ad3-b51c-a563d116c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "emb_cols = jokes.columns[jokes.columns.str.contains('embedding_')]\n",
    "cs = cosine_similarity(jokes[emb_cols].values)\n",
    "cs = pd.DataFrame(cs)\n",
    "print(cs.shape)\n",
    "\n",
    "cs2 = pd.melt(cs.reset_index(), id_vars='index', var_name='other_index',value_name='cosine_sim')\n",
    "cs2['left'] = jokes.loc[cs2['index']]['q_a'].values\n",
    "cs2['right'] = jokes.loc[cs2['other_index']]['q_a'].values\n",
    "cs2['joined_index'] = np.where(\n",
    "    cs2['index'] <= cs2['other_index'],\n",
    "    cs2['index'].astype('str') + '_' + cs2['other_index'].astype('str'),\n",
    "    cs2['other_index'].astype('str') + '_' + cs2['index'].astype('str'),\n",
    ")\n",
    "cs2['joined_index_rank'] = cs2.groupby('joined_index')['index'].rank()\n",
    "\n",
    "cs2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe566c-6868-47c4-bb9f-23fe4d47881d",
   "metadata": {},
   "source": [
    "### Remove duplicates using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7351e5-8e40-42ec-b1a4-4671fb9ea87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ae50c-32d2-4842-8454-f7a59dbca16c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display_html\n",
    "\n",
    "possible_dups =(\n",
    "    cs2\n",
    "    .query('index != other_index')\n",
    "    .query('cosine_sim > @threshold')\n",
    "    .sort_values('cosine_sim', ascending=False)\n",
    ")\n",
    "\n",
    "with pd.option_context('max_colwidth', 100) as cont:\n",
    "    display_html(possible_dups.to_html(),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47570e85-b775-4d91-a89c-d98804db3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indices = possible_dups.query('joined_index_rank == 1')['other_index'].values\n",
    "\n",
    "temp_df = jokes.copy(deep=True).drop(drop_indices, axis=0)\n",
    "jokes.shape[0], temp_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff5ac3-0507-495d-afb9-3bb5d9de150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.assign(\n",
    "    prompt=temp_df['question'].str.strip() + PROMPT_TEXT,\n",
    "    completion=' ' + temp_df['answer'].str.strip() + '###',\n",
    ")[['prompt','completion']].to_csv('../data/anti_jokes_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d2833-41fb-4ce0-9216-6403f7f3255d",
   "metadata": {},
   "source": [
    "## Process for openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eec5d7-e060-4ba1-94b7-069ee5f448cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fd5ec-4ea9-427a-8090-da595b797add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/anti_jokes_clean.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb87b89-7ca8-4de6-a5bf-1324bca08525",
   "metadata": {},
   "outputs": [],
   "source": [
    "(temp_df['q_a'].str.count(' ') + 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac6de6-94cf-4c86-acb1-97118df864ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"data/anti_jokes_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe08b0-25c2-4577-98e4-86163525df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !openai api fine_tunes.create -t \"data/anti_jokes_clean_prepared.jsonl\" -m \"davinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385f643-c68e-4a6b-929a-26569c15412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecadca-2302-4b31-a6a0-9ccdebfae758",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!openai api fine_tunes.get -i <ID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed12192-e463-4893-bb8c-10a910d36d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd257596-58c8-4a1c-916d-0b93cafddf44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7 (default, Mar 26 2020, 10:32:53) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7bd7910e2b67e8af55c6d0d0876bce0060c25aec0ec1c82f29a1c9a158bc9cdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
